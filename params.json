{"name":"Naive-bayes","tagline":"数据挖掘-朴素贝叶斯算法","body":"###背景\r\n分类问题在数据挖掘领域是一个重要的议题，目前比较流行的包括逻辑回归、随机森林、决策树、GBDT等方法，当然还有朴素贝叶斯（Naive Bayes）。朴素贝叶斯算法原理基于贝叶斯原理，[bayes](https://en.wikipedia.org/wiki/Bayes%27_theorem)告诉我们两个条件概率之间的关系（P(B|A) = P(A|B)*P(B) / P(A)），朴素贝叶斯算法原理虽然比较简单，并且在分类场景中，也有很好的效果。\r\n\r\n###综述\r\n朴素贝叶斯算法简单说就是用概率问题去预测归属问题，比如说医生看病，医生通过病人描述的病情去判断该病人得了什么病。在这个过程中，医生需要了解病人的病情：是否头痛、是否发烧（选择特征属性），然后根据多年的行医经验去判断病因（形成判断模型，选择概率最大的一项）。\r\n\r\n假设C={y1,y2,y3...yn}表示的是分类结果的集合，每一个yi都表示的是一种分类结果。另外，还有一组变量X={x1,x2,x3...xm}，现在我们需要根据这组变量X去判断结果C\r\n![](https://upload.wikimedia.org/math/7/b/d/7bda6ebeee34c32bc16cf0239067409c.png)\r\nP(C|x1,x2,x3...xn)表示的是先验概率，即在x1,x2,x3...xn在一类情况下，出现某类问题的概率值大小。还以医生判断病情的例子来说，如果判断病人的病情的特征属性有：x1=“头痛”、x2=“流鼻涕”、x3=“感觉发冷”，那么P(C=\"感冒\"|x1,x2,x3)就表示病情为“头痛，流鼻涕，感觉发冷”这种情况下“感冒”的概率大小。再回到上面的公式，如上面的公式所看到的的，因为对于某类特定场景，x1...xn是确定的，所以只有分子的大小是变化，而分子又可以算成：\r\n![](https://upload.wikimedia.org/math/7/4/5/745c7a4bfdf16584aff54a70a0c4268b.png)\r\n![](https://upload.wikimedia.org/math/1/7/3/1734b2d88a1e0c283d955b1486e178d0.png)\r\n注意：上述换算会有一个前提，即{x1,x2,x3...xn}相互之间是独立的，那么分类判断主要依赖计算\r\n![](https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification/Na%C3%AFve_Bayes)\r\n\r\n`library(e1071)\r\ndata(iris)\r\nclassifier<-naiveBayes(iris[,1:4], iris[,5]) \r\ntable(predict(classifier, iris[,-5]), iris[,5])\r\n`\r\n\r\n###上述计算的问题\r\n（1）朴素贝叶斯原理是为了计算显得更简单点，但是它有假设条件，即特征属性之间是独立的，但是这种情况在实际场景中是不存在的；（2）上述先验概率计算是基于变量是离散型基础，如果是连续性变量，一般需要做分区或者是根据变量的正态分布特征去计算对应的先验概率值；（3）如果数据离散太严重，会出现（P=0）的情况，需要用到拉普拉斯平滑法处理\r\n\r\n***\r\n参考文档\r\n1、https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification/Na%C3%AFve_Bayes\r\n2、http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html\r\n3、http://www.ruanyifeng.com/blog/2013/12/naive_bayes_classifier.html\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}